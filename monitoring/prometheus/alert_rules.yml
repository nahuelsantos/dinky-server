groups:
  # Infrastructure Health Alerts
  - name: infrastructure
    rules:
      # High CPU Usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is above 80% for more than 2 minutes on {{ $labels.instance }}"

      # Critical CPU Usage  
      - alert: CriticalCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 95
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Critical CPU usage detected"
          description: "CPU usage is above 95% for more than 5 minutes on {{ $labels.instance }}"

      # High Memory Usage
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is above 80% for more than 2 minutes on {{ $labels.instance }}"

      # Critical Memory Usage
      - alert: CriticalMemoryUsage  
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 95
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Critical memory usage detected"
          description: "Memory usage is above 95% for more than 5 minutes on {{ $labels.instance }}"

      # Low Disk Space
      - alert: LowDiskSpace
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 80
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Low disk space detected"
          description: "Disk usage is above 80% on {{ $labels.device }} ({{ $labels.mountpoint }}) on {{ $labels.instance }}"

      # Critical Disk Space
      - alert: CriticalDiskSpace
        expr: (1 - (node_filesystem_avail_bytes{fstype!="tmpfs"} / node_filesystem_size_bytes{fstype!="tmpfs"})) * 100 > 95
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Critical disk space detected"
          description: "Disk usage is above 95% on {{ $labels.device }} ({{ $labels.mountpoint }}) on {{ $labels.instance }}"

  # Container Health Alerts
  - name: containers
    rules:
      # Container Monitoring Down (cAdvisor)
      - alert: ContainerMonitoringDown
        expr: up{job="docker"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Container monitoring is down"
          description: "cAdvisor container monitoring is not responding on {{ $labels.instance }}"

      # Container High CPU
      - alert: ContainerHighCPU
        expr: rate(container_cpu_usage_seconds_total[5m]) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Container high CPU usage"
          description: "Container {{ $labels.name }} CPU usage is above 80% for more than 2 minutes"

      # Container High Memory
      - alert: ContainerHighMemory
        expr: (container_memory_usage_bytes / container_spec_memory_limit_bytes) * 100 > 80
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Container high memory usage"
          description: "Container {{ $labels.name }} memory usage is above 80% of its limit for more than 2 minutes"

      # Container Restart Loop
      - alert: ContainerRestartLoop
        expr: increase(container_start_time_seconds[1h]) > 5
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "Container restart loop detected"
          description: "Container {{ $labels.name }} has restarted more than 5 times in the last hour"

  # Core Services Health - Only critical infrastructure services
  - name: core_services
    rules:
      # Grafana Down
      - alert: GrafanaDown
        expr: up{job="grafana"} == 0
        for: 2m
        labels:
          severity: critical
        annotations:
          summary: "Grafana is down"
          description: "Grafana dashboard service is not responding"

      # Prometheus Down (self-monitoring)
      - alert: PrometheusDown
        expr: up{job="prometheus"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Prometheus is down"
          description: "Prometheus monitoring service is not responding"

      # Loki Down
      - alert: LokiDown
        expr: up{job="loki"} == 0
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "Loki log aggregation is down"
          description: "Loki log aggregation service is not responding"

      # Traefik Down
      - alert: TraefikDown
        expr: up{job="traefik"} == 0
        for: 1m
        labels:
          severity: critical
        annotations:
          summary: "Traefik reverse proxy is down"
          description: "Traefik reverse proxy service is not responding - all web services may be inaccessible"

  # Network and Load Alerts
  - name: network
    rules:
      # High Network Traffic
      - alert: HighNetworkTraffic
        expr: rate(node_network_receive_bytes_total[5m]) + rate(node_network_transmit_bytes_total[5m]) > 100 * 1024 * 1024
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High network traffic detected"
          description: "Network traffic is above 100MB/s for more than 5 minutes on {{ $labels.instance }}"

      # High Load Average
      - alert: HighLoadAverage
        expr: node_load15 > 2
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High system load detected"
          description: "15-minute load average is above 2 for more than 5 minutes on {{ $labels.instance }}"

      # Traefik High Response Time
      - alert: TraefikHighResponseTime
        expr: histogram_quantile(0.95, rate(traefik_service_request_duration_seconds_bucket[5m])) > 1
        for: 2m
        labels:
          severity: warning
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is above 1 second for service {{ $labels.service }}"

  # Website and Service Monitoring - Your business services
  - name: dinky_services
    rules:
      # Contact API Down
      - alert: ContactAPIDown
        expr: up{job="contact-api"} == 0
        for: 2m
        labels:
          severity: critical
          service: contact-api
        annotations:
          summary: "Contact API service is down"
          description: "Contact API has been down for more than 2 minutes - contact forms will not work on nahuelsantos.com and loopingbyte.com"

      # Contact API High Response Time
      - alert: ContactAPIHighResponseTime
        expr: histogram_quantile(0.95, rate(gin_request_duration_seconds_bucket{job="contact-api"}[5m])) > 2
        for: 3m
        labels:
          severity: warning
          service: contact-api
        annotations:
          summary: "Contact API high response time"
          description: "Contact API 95th percentile response time is {{ $value }}s (above 2s threshold)"

      # Contact API High Error Rate
      - alert: ContactAPIHighErrorRate
        expr: rate(gin_requests_total{job="contact-api",status=~"5.."}[5m]) / rate(gin_requests_total{job="contact-api"}[5m]) * 100 > 5
        for: 5m
        labels:
          severity: warning
          service: contact-api
        annotations:
          summary: "Contact API high error rate"
          description: "Contact API error rate is {{ $value }}% over the last 5 minutes (above 5% threshold)"

      # Contact API Memory Usage High
      - alert: ContactAPIHighMemory
        expr: (container_memory_usage_bytes{name="contact-api"} / container_spec_memory_limit_bytes{name="contact-api"}) * 100 > 80
        for: 5m
        labels:
          severity: warning
          service: contact-api
        annotations:
          summary: "Contact API high memory usage"
          description: "Contact API memory usage is {{ $value }}% of its limit"

      # External Website Down (covers all your public sites)
      - alert: WebsiteDown
        expr: probe_success{job="website-probes"} == 0
        for: 1m
        labels:
          severity: critical
          service: website
        annotations:
          summary: "Website {{ $labels.instance }} is down"
          description: "Website {{ $labels.instance }} has been unreachable for more than 1 minute"

      # CV Site Special Alert (faster response for professional site)
      - alert: CVSiteDown
        expr: probe_success{job="website-probes",instance="https://cv.nahuelsantos.com"} == 0
        for: 30s
        labels:
          severity: critical
          service: cv-site
        annotations:
          summary: "CV website is down"
          description: "Your professional CV website (cv.nahuelsantos.com) has been down for 30 seconds - this impacts your professional presence"

      # Website Slow Response (unified threshold)
      - alert: WebsiteSlowResponse
        expr: probe_duration_seconds{job="website-probes"} > 2
        for: 2m
        labels:
          severity: warning
          service: website
        annotations:
          summary: "Website {{ $labels.instance }} slow response"
          description: "Website {{ $labels.instance }} response time is above 2 seconds for 2 minutes (current: {{ $value }}s)"

      # Website HTTP Error
      - alert: WebsiteHTTPError
        expr: probe_http_status_code{job="website-probes"} >= 400
        for: 2m
        labels:
          severity: warning
          service: website
        annotations:
          summary: "Website HTTP error"
          description: "Website {{ $labels.instance }} returned HTTP {{ $value }} for more than 2 minutes"

      # SSL Certificate Expiring
      - alert: WebsiteSSLCertExpiringSoon
        expr: probe_ssl_earliest_cert_expiry{job="website-probes"} - time() < 86400 * 7
        for: 5m
        labels:
          severity: warning
          service: website
        annotations:
          summary: "SSL certificate expiring soon"
          description: "SSL certificate for {{ $labels.instance }} expires in less than 7 days"

      # Internal Container Health (for containers behind Traefik)
      - alert: InternalContainerUnreachable
        expr: probe_success{job=~".*-http-internal"} == 0
        for: 3m
        labels:
          severity: warning
          service: container
        annotations:
          summary: "Internal container unreachable"
          description: "Container {{ $labels.instance }} is not responding to internal health checks for 3 minutes" 